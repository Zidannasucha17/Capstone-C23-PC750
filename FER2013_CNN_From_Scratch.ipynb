{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE6DKWUp9UG6"
      },
      "outputs": [],
      "source": [
        " ! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "CbkZgvoR9Voc",
        "outputId": "636fdfb6-a375-4fd4-a1e7-e6585580f922"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eb7695ec-bd95-4690-9d19-ce5294e8dbc8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-eb7695ec-bd95-4690-9d19-ce5294e8dbc8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"erlanggasatrioagung\",\"key\":\"3b87a48f5cff18c3f6741632ec900bfb\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5HQEgd29bNG"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwOtr-9K9h2y"
      },
      "outputs": [],
      "source": [
        "! cp '/content/kaggle.json' ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEwS1nsI-v_O"
      },
      "outputs": [],
      "source": [
        " ! chmod 600 /content/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6isZaMn-9xO",
        "outputId": "8a7373ce-ba9a-4b17-e81d-f0af94416dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading fer2013.zip to /content\n",
            " 96% 58.0M/60.3M [00:03<00:00, 24.4MB/s]\n",
            "100% 60.3M/60.3M [00:03<00:00, 17.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets download -d msambare/fer2013"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So8eIPtt_wiT"
      },
      "outputs": [],
      "source": [
        "!mkdir Dataset\n",
        "!cp /content/fer2013.zip /content/Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OM4XlXSDAGx8"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/Dataset/fer2013.zip -d /content/Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmMx0vpBH9Wj",
        "outputId": "7db4a135-c280-4fc6-824f-5f52e01a2e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28709 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "img_size = (48, 48)\n",
        "BATCH_SIZE = 32\n",
        "train_dir = '/content/Dataset/train'\n",
        "val_dir = '/content/Dataset/test'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=img_size,\n",
        "                                               class_mode='categorical',\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               color_mode='grayscale',\n",
        "                                               subset='training') #setting_training_data\n",
        "\n",
        "validation_data = validation_datagen.flow_from_directory(val_dir,\n",
        "                                                         target_size=img_size,\n",
        "                                                         class_mode='categorical',\n",
        "                                                         batch_size=BATCH_SIZE,\n",
        "                                                         color_mode='grayscale') #setting_validation_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67ycEZTxk7N3",
        "outputId": "fef0512d-60c7-4af8-c009-6cdbfbe8a4de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 46, 46, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 23, 23, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 21, 21, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 2, 2, 128)         147584    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 1, 1, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 1799      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 293,831\n",
            "Trainable params: 293,831\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dropout, Flatten, Dense, MaxPooling2D\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape = (48, 48, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = [\"accuracy\",\n",
        "               tf.keras.metrics.Precision(),\n",
        "               tf.keras.metrics.Recall()]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVQ7opfFnWeV",
        "outputId": "aecfbaf7-0da1-4a98-82b2-9f4cd438849e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.5736 - accuracy: 0.3898 - precision: 0.6678 - recall: 0.1260 - val_loss: 1.4473 - val_accuracy: 0.4436 - val_precision: 0.8404 - val_recall: 0.1403\n",
            "Epoch 2/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.5138 - accuracy: 0.4163 - precision: 0.7015 - recall: 0.1603 - val_loss: 1.4300 - val_accuracy: 0.4436 - val_precision: 0.7658 - val_recall: 0.2080\n",
            "Epoch 3/400\n",
            "897/897 [==============================] - 26s 28ms/step - loss: 1.4797 - accuracy: 0.4270 - precision: 0.7081 - recall: 0.1749 - val_loss: 1.3694 - val_accuracy: 0.4771 - val_precision: 0.7903 - val_recall: 0.2125\n",
            "Epoch 4/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.4496 - accuracy: 0.4431 - precision: 0.7140 - recall: 0.1917 - val_loss: 1.3485 - val_accuracy: 0.4859 - val_precision: 0.7938 - val_recall: 0.2160\n",
            "Epoch 5/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.4287 - accuracy: 0.4481 - precision: 0.7234 - recall: 0.2031 - val_loss: 1.3469 - val_accuracy: 0.4734 - val_precision: 0.7554 - val_recall: 0.2469\n",
            "Epoch 6/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.4134 - accuracy: 0.4549 - precision: 0.7268 - recall: 0.2106 - val_loss: 1.3109 - val_accuracy: 0.4907 - val_precision: 0.7616 - val_recall: 0.2648\n",
            "Epoch 7/400\n",
            "897/897 [==============================] - 26s 28ms/step - loss: 1.4000 - accuracy: 0.4618 - precision: 0.7225 - recall: 0.2149 - val_loss: 1.2939 - val_accuracy: 0.5024 - val_precision: 0.7887 - val_recall: 0.2515\n",
            "Epoch 8/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.3854 - accuracy: 0.4669 - precision: 0.7265 - recall: 0.2249 - val_loss: 1.3007 - val_accuracy: 0.4979 - val_precision: 0.7942 - val_recall: 0.2508\n",
            "Epoch 9/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.3778 - accuracy: 0.4739 - precision: 0.7235 - recall: 0.2338 - val_loss: 1.2871 - val_accuracy: 0.5103 - val_precision: 0.8396 - val_recall: 0.2271\n",
            "Epoch 10/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.3631 - accuracy: 0.4781 - precision: 0.7217 - recall: 0.2406 - val_loss: 1.2763 - val_accuracy: 0.5127 - val_precision: 0.8078 - val_recall: 0.2468\n",
            "Epoch 11/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.3567 - accuracy: 0.4828 - precision: 0.7223 - recall: 0.2430 - val_loss: 1.2783 - val_accuracy: 0.5029 - val_precision: 0.7615 - val_recall: 0.2868\n",
            "Epoch 12/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.3470 - accuracy: 0.4846 - precision: 0.7239 - recall: 0.2525 - val_loss: 1.2674 - val_accuracy: 0.5110 - val_precision: 0.8041 - val_recall: 0.2490\n",
            "Epoch 13/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.3415 - accuracy: 0.4864 - precision: 0.7302 - recall: 0.2511 - val_loss: 1.2368 - val_accuracy: 0.5253 - val_precision: 0.8088 - val_recall: 0.2680\n",
            "Epoch 14/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.3335 - accuracy: 0.4885 - precision: 0.7331 - recall: 0.2568 - val_loss: 1.2546 - val_accuracy: 0.5177 - val_precision: 0.8219 - val_recall: 0.2517\n",
            "Epoch 15/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.3312 - accuracy: 0.4939 - precision: 0.7313 - recall: 0.2613 - val_loss: 1.2367 - val_accuracy: 0.5311 - val_precision: 0.8170 - val_recall: 0.2672\n",
            "Epoch 16/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.3188 - accuracy: 0.4964 - precision: 0.7334 - recall: 0.2663 - val_loss: 1.2445 - val_accuracy: 0.5123 - val_precision: 0.7476 - val_recall: 0.3170\n",
            "Epoch 17/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.3168 - accuracy: 0.4963 - precision: 0.7288 - recall: 0.2685 - val_loss: 1.2394 - val_accuracy: 0.5240 - val_precision: 0.7981 - val_recall: 0.2725\n",
            "Epoch 18/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.3116 - accuracy: 0.5027 - precision: 0.7290 - recall: 0.2738 - val_loss: 1.2330 - val_accuracy: 0.5232 - val_precision: 0.7666 - val_recall: 0.2905\n",
            "Epoch 19/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.3058 - accuracy: 0.5026 - precision: 0.7296 - recall: 0.2781 - val_loss: 1.2397 - val_accuracy: 0.5258 - val_precision: 0.7843 - val_recall: 0.2902\n",
            "Epoch 20/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.3108 - accuracy: 0.5017 - precision: 0.7308 - recall: 0.2741 - val_loss: 1.2102 - val_accuracy: 0.5359 - val_precision: 0.8028 - val_recall: 0.2902\n",
            "Epoch 21/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.3069 - accuracy: 0.5044 - precision: 0.7373 - recall: 0.2764 - val_loss: 1.2370 - val_accuracy: 0.5377 - val_precision: 0.8503 - val_recall: 0.2369\n",
            "Epoch 22/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2995 - accuracy: 0.5064 - precision: 0.7277 - recall: 0.2810 - val_loss: 1.2144 - val_accuracy: 0.5421 - val_precision: 0.8051 - val_recall: 0.2778\n",
            "Epoch 23/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2928 - accuracy: 0.5107 - precision: 0.7341 - recall: 0.2865 - val_loss: 1.2085 - val_accuracy: 0.5310 - val_precision: 0.7894 - val_recall: 0.3022\n",
            "Epoch 24/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2905 - accuracy: 0.5066 - precision: 0.7326 - recall: 0.2830 - val_loss: 1.2431 - val_accuracy: 0.5240 - val_precision: 0.7989 - val_recall: 0.2677\n",
            "Epoch 25/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2870 - accuracy: 0.5127 - precision: 0.7320 - recall: 0.2912 - val_loss: 1.2012 - val_accuracy: 0.5370 - val_precision: 0.7855 - val_recall: 0.2998\n",
            "Epoch 26/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2834 - accuracy: 0.5115 - precision: 0.7354 - recall: 0.2915 - val_loss: 1.2001 - val_accuracy: 0.5452 - val_precision: 0.8121 - val_recall: 0.2895\n",
            "Epoch 27/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2851 - accuracy: 0.5105 - precision: 0.7286 - recall: 0.2907 - val_loss: 1.2038 - val_accuracy: 0.5360 - val_precision: 0.8002 - val_recall: 0.2939\n",
            "Epoch 28/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2726 - accuracy: 0.5198 - precision: 0.7407 - recall: 0.2961 - val_loss: 1.2020 - val_accuracy: 0.5479 - val_precision: 0.8214 - val_recall: 0.2715\n",
            "Epoch 29/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2757 - accuracy: 0.5139 - precision: 0.7324 - recall: 0.2973 - val_loss: 1.1948 - val_accuracy: 0.5469 - val_precision: 0.8152 - val_recall: 0.2819\n",
            "Epoch 30/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2727 - accuracy: 0.5184 - precision: 0.7386 - recall: 0.2991 - val_loss: 1.1906 - val_accuracy: 0.5509 - val_precision: 0.8203 - val_recall: 0.2923\n",
            "Epoch 31/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2701 - accuracy: 0.5133 - precision: 0.7358 - recall: 0.2984 - val_loss: 1.1908 - val_accuracy: 0.5518 - val_precision: 0.8339 - val_recall: 0.2808\n",
            "Epoch 32/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2705 - accuracy: 0.5173 - precision: 0.7327 - recall: 0.2992 - val_loss: 1.1947 - val_accuracy: 0.5559 - val_precision: 0.8251 - val_recall: 0.2889\n",
            "Epoch 33/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2707 - accuracy: 0.5207 - precision: 0.7332 - recall: 0.3034 - val_loss: 1.1824 - val_accuracy: 0.5522 - val_precision: 0.8050 - val_recall: 0.3052\n",
            "Epoch 34/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2644 - accuracy: 0.5211 - precision: 0.7340 - recall: 0.3047 - val_loss: 1.1781 - val_accuracy: 0.5569 - val_precision: 0.7943 - val_recall: 0.3199\n",
            "Epoch 35/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2631 - accuracy: 0.5212 - precision: 0.7336 - recall: 0.3039 - val_loss: 1.1812 - val_accuracy: 0.5473 - val_precision: 0.8042 - val_recall: 0.3089\n",
            "Epoch 36/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2600 - accuracy: 0.5233 - precision: 0.7365 - recall: 0.3064 - val_loss: 1.1972 - val_accuracy: 0.5576 - val_precision: 0.8455 - val_recall: 0.2740\n",
            "Epoch 37/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2580 - accuracy: 0.5244 - precision: 0.7364 - recall: 0.3068 - val_loss: 1.1840 - val_accuracy: 0.5511 - val_precision: 0.8069 - val_recall: 0.3032\n",
            "Epoch 38/400\n",
            "897/897 [==============================] - 26s 28ms/step - loss: 1.2581 - accuracy: 0.5205 - precision: 0.7366 - recall: 0.3071 - val_loss: 1.1873 - val_accuracy: 0.5568 - val_precision: 0.8383 - val_recall: 0.2864\n",
            "Epoch 39/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2538 - accuracy: 0.5235 - precision: 0.7422 - recall: 0.3062 - val_loss: 1.1643 - val_accuracy: 0.5573 - val_precision: 0.8043 - val_recall: 0.3149\n",
            "Epoch 40/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2552 - accuracy: 0.5256 - precision: 0.7352 - recall: 0.3107 - val_loss: 1.1932 - val_accuracy: 0.5501 - val_precision: 0.8434 - val_recall: 0.2727\n",
            "Epoch 41/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2530 - accuracy: 0.5236 - precision: 0.7384 - recall: 0.3093 - val_loss: 1.2033 - val_accuracy: 0.5379 - val_precision: 0.8165 - val_recall: 0.2856\n",
            "Epoch 42/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2514 - accuracy: 0.5294 - precision: 0.7415 - recall: 0.3132 - val_loss: 1.1956 - val_accuracy: 0.5495 - val_precision: 0.8106 - val_recall: 0.2980\n",
            "Epoch 43/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2512 - accuracy: 0.5267 - precision: 0.7378 - recall: 0.3108 - val_loss: 1.1830 - val_accuracy: 0.5525 - val_precision: 0.8345 - val_recall: 0.2920\n",
            "Epoch 44/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2465 - accuracy: 0.5247 - precision: 0.7341 - recall: 0.3099 - val_loss: 1.1753 - val_accuracy: 0.5527 - val_precision: 0.7930 - val_recall: 0.3260\n",
            "Epoch 45/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2470 - accuracy: 0.5270 - precision: 0.7386 - recall: 0.3150 - val_loss: 1.1739 - val_accuracy: 0.5575 - val_precision: 0.8286 - val_recall: 0.2893\n",
            "Epoch 46/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2504 - accuracy: 0.5264 - precision: 0.7360 - recall: 0.3105 - val_loss: 1.1681 - val_accuracy: 0.5530 - val_precision: 0.8222 - val_recall: 0.3071\n",
            "Epoch 47/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2434 - accuracy: 0.5270 - precision: 0.7382 - recall: 0.3153 - val_loss: 1.1706 - val_accuracy: 0.5509 - val_precision: 0.8118 - val_recall: 0.3111\n",
            "Epoch 48/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2446 - accuracy: 0.5278 - precision: 0.7386 - recall: 0.3142 - val_loss: 1.1782 - val_accuracy: 0.5582 - val_precision: 0.8113 - val_recall: 0.2939\n",
            "Epoch 49/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2377 - accuracy: 0.5293 - precision: 0.7427 - recall: 0.3174 - val_loss: 1.1841 - val_accuracy: 0.5536 - val_precision: 0.8520 - val_recall: 0.2803\n",
            "Epoch 50/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2392 - accuracy: 0.5312 - precision: 0.7363 - recall: 0.3198 - val_loss: 1.2104 - val_accuracy: 0.5488 - val_precision: 0.8660 - val_recall: 0.2416\n",
            "Epoch 51/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2450 - accuracy: 0.5315 - precision: 0.7420 - recall: 0.3161 - val_loss: 1.1577 - val_accuracy: 0.5621 - val_precision: 0.8194 - val_recall: 0.3096\n",
            "Epoch 52/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2372 - accuracy: 0.5315 - precision: 0.7407 - recall: 0.3217 - val_loss: 1.1554 - val_accuracy: 0.5618 - val_precision: 0.8106 - val_recall: 0.3170\n",
            "Epoch 53/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2333 - accuracy: 0.5339 - precision: 0.7394 - recall: 0.3217 - val_loss: 1.1741 - val_accuracy: 0.5495 - val_precision: 0.8118 - val_recall: 0.3124\n",
            "Epoch 54/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2335 - accuracy: 0.5343 - precision: 0.7410 - recall: 0.3228 - val_loss: 1.1726 - val_accuracy: 0.5571 - val_precision: 0.8474 - val_recall: 0.2898\n",
            "Epoch 55/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2376 - accuracy: 0.5313 - precision: 0.7403 - recall: 0.3205 - val_loss: 1.1627 - val_accuracy: 0.5587 - val_precision: 0.8252 - val_recall: 0.3048\n",
            "Epoch 56/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2330 - accuracy: 0.5347 - precision: 0.7440 - recall: 0.3234 - val_loss: 1.1704 - val_accuracy: 0.5580 - val_precision: 0.8094 - val_recall: 0.3110\n",
            "Epoch 57/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2316 - accuracy: 0.5312 - precision: 0.7406 - recall: 0.3226 - val_loss: 1.1827 - val_accuracy: 0.5532 - val_precision: 0.8071 - val_recall: 0.3071\n",
            "Epoch 58/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2342 - accuracy: 0.5319 - precision: 0.7429 - recall: 0.3239 - val_loss: 1.1794 - val_accuracy: 0.5562 - val_precision: 0.8518 - val_recall: 0.2807\n",
            "Epoch 59/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2319 - accuracy: 0.5323 - precision: 0.7403 - recall: 0.3229 - val_loss: 1.1646 - val_accuracy: 0.5709 - val_precision: 0.8349 - val_recall: 0.2864\n",
            "Epoch 60/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.2300 - accuracy: 0.5339 - precision: 0.7395 - recall: 0.3189 - val_loss: 1.1628 - val_accuracy: 0.5603 - val_precision: 0.8256 - val_recall: 0.3083\n",
            "Epoch 61/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2249 - accuracy: 0.5365 - precision: 0.7407 - recall: 0.3265 - val_loss: 1.1789 - val_accuracy: 0.5592 - val_precision: 0.8283 - val_recall: 0.2921\n",
            "Epoch 62/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2285 - accuracy: 0.5335 - precision: 0.7443 - recall: 0.3241 - val_loss: 1.1590 - val_accuracy: 0.5689 - val_precision: 0.8485 - val_recall: 0.2930\n",
            "Epoch 63/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2228 - accuracy: 0.5350 - precision: 0.7429 - recall: 0.3271 - val_loss: 1.1477 - val_accuracy: 0.5615 - val_precision: 0.7953 - val_recall: 0.3426\n",
            "Epoch 64/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2311 - accuracy: 0.5336 - precision: 0.7386 - recall: 0.3230 - val_loss: 1.1599 - val_accuracy: 0.5582 - val_precision: 0.8204 - val_recall: 0.3027\n",
            "Epoch 65/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2328 - accuracy: 0.5334 - precision: 0.7423 - recall: 0.3233 - val_loss: 1.1594 - val_accuracy: 0.5635 - val_precision: 0.8148 - val_recall: 0.3172\n",
            "Epoch 66/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2251 - accuracy: 0.5345 - precision: 0.7419 - recall: 0.3241 - val_loss: 1.1658 - val_accuracy: 0.5585 - val_precision: 0.8283 - val_recall: 0.3062\n",
            "Epoch 67/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2257 - accuracy: 0.5386 - precision: 0.7409 - recall: 0.3256 - val_loss: 1.1637 - val_accuracy: 0.5639 - val_precision: 0.8197 - val_recall: 0.3026\n",
            "Epoch 68/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2257 - accuracy: 0.5386 - precision: 0.7389 - recall: 0.3258 - val_loss: 1.1706 - val_accuracy: 0.5571 - val_precision: 0.8072 - val_recall: 0.3072\n",
            "Epoch 69/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2193 - accuracy: 0.5389 - precision: 0.7432 - recall: 0.3328 - val_loss: 1.1622 - val_accuracy: 0.5693 - val_precision: 0.8099 - val_recall: 0.3097\n",
            "Epoch 70/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2161 - accuracy: 0.5413 - precision: 0.7414 - recall: 0.3314 - val_loss: 1.1482 - val_accuracy: 0.5642 - val_precision: 0.8132 - val_recall: 0.3280\n",
            "Epoch 71/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2218 - accuracy: 0.5382 - precision: 0.7405 - recall: 0.3287 - val_loss: 1.1892 - val_accuracy: 0.5544 - val_precision: 0.7968 - val_recall: 0.2992\n",
            "Epoch 72/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2207 - accuracy: 0.5357 - precision: 0.7442 - recall: 0.3308 - val_loss: 1.1779 - val_accuracy: 0.5589 - val_precision: 0.8301 - val_recall: 0.2898\n",
            "Epoch 73/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2152 - accuracy: 0.5390 - precision: 0.7416 - recall: 0.3321 - val_loss: 1.1650 - val_accuracy: 0.5622 - val_precision: 0.8322 - val_recall: 0.3030\n",
            "Epoch 74/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2200 - accuracy: 0.5390 - precision: 0.7443 - recall: 0.3343 - val_loss: 1.1722 - val_accuracy: 0.5600 - val_precision: 0.8243 - val_recall: 0.2997\n",
            "Epoch 75/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2184 - accuracy: 0.5352 - precision: 0.7462 - recall: 0.3308 - val_loss: 1.1395 - val_accuracy: 0.5684 - val_precision: 0.8186 - val_recall: 0.3230\n",
            "Epoch 76/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2182 - accuracy: 0.5389 - precision: 0.7469 - recall: 0.3321 - val_loss: 1.1742 - val_accuracy: 0.5661 - val_precision: 0.8407 - val_recall: 0.2885\n",
            "Epoch 77/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2140 - accuracy: 0.5442 - precision: 0.7484 - recall: 0.3365 - val_loss: 1.1569 - val_accuracy: 0.5642 - val_precision: 0.8369 - val_recall: 0.3029\n",
            "Epoch 78/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2219 - accuracy: 0.5379 - precision: 0.7438 - recall: 0.3285 - val_loss: 1.1658 - val_accuracy: 0.5586 - val_precision: 0.8243 - val_recall: 0.3071\n",
            "Epoch 79/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2179 - accuracy: 0.5358 - precision: 0.7451 - recall: 0.3315 - val_loss: 1.1623 - val_accuracy: 0.5663 - val_precision: 0.8215 - val_recall: 0.3094\n",
            "Epoch 80/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2135 - accuracy: 0.5430 - precision: 0.7473 - recall: 0.3358 - val_loss: 1.1434 - val_accuracy: 0.5654 - val_precision: 0.8219 - val_recall: 0.3199\n",
            "Epoch 81/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2135 - accuracy: 0.5412 - precision: 0.7422 - recall: 0.3324 - val_loss: 1.1582 - val_accuracy: 0.5629 - val_precision: 0.8175 - val_recall: 0.3206\n",
            "Epoch 82/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2132 - accuracy: 0.5445 - precision: 0.7384 - recall: 0.3379 - val_loss: 1.1676 - val_accuracy: 0.5656 - val_precision: 0.8126 - val_recall: 0.3032\n",
            "Epoch 83/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2128 - accuracy: 0.5447 - precision: 0.7417 - recall: 0.3386 - val_loss: 1.1732 - val_accuracy: 0.5684 - val_precision: 0.8493 - val_recall: 0.2799\n",
            "Epoch 84/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2144 - accuracy: 0.5403 - precision: 0.7424 - recall: 0.3322 - val_loss: 1.1450 - val_accuracy: 0.5711 - val_precision: 0.8174 - val_recall: 0.3248\n",
            "Epoch 85/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2160 - accuracy: 0.5412 - precision: 0.7461 - recall: 0.3342 - val_loss: 1.1476 - val_accuracy: 0.5727 - val_precision: 0.8232 - val_recall: 0.3189\n",
            "Epoch 86/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2083 - accuracy: 0.5413 - precision: 0.7452 - recall: 0.3368 - val_loss: 1.1459 - val_accuracy: 0.5731 - val_precision: 0.8207 - val_recall: 0.3224\n",
            "Epoch 87/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2152 - accuracy: 0.5375 - precision: 0.7413 - recall: 0.3340 - val_loss: 1.1475 - val_accuracy: 0.5628 - val_precision: 0.8224 - val_recall: 0.3249\n",
            "Epoch 88/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2099 - accuracy: 0.5429 - precision: 0.7471 - recall: 0.3365 - val_loss: 1.1597 - val_accuracy: 0.5596 - val_precision: 0.8178 - val_recall: 0.3150\n",
            "Epoch 89/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2094 - accuracy: 0.5411 - precision: 0.7428 - recall: 0.3367 - val_loss: 1.1599 - val_accuracy: 0.5661 - val_precision: 0.8036 - val_recall: 0.3318\n",
            "Epoch 90/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2083 - accuracy: 0.5451 - precision: 0.7441 - recall: 0.3387 - val_loss: 1.1492 - val_accuracy: 0.5731 - val_precision: 0.8460 - val_recall: 0.3034\n",
            "Epoch 91/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2106 - accuracy: 0.5420 - precision: 0.7413 - recall: 0.3388 - val_loss: 1.1414 - val_accuracy: 0.5720 - val_precision: 0.8323 - val_recall: 0.3234\n",
            "Epoch 92/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2067 - accuracy: 0.5463 - precision: 0.7485 - recall: 0.3404 - val_loss: 1.1614 - val_accuracy: 0.5728 - val_precision: 0.8238 - val_recall: 0.3092\n",
            "Epoch 93/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2072 - accuracy: 0.5472 - precision: 0.7501 - recall: 0.3396 - val_loss: 1.1577 - val_accuracy: 0.5692 - val_precision: 0.8231 - val_recall: 0.3108\n",
            "Epoch 94/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2117 - accuracy: 0.5432 - precision: 0.7397 - recall: 0.3366 - val_loss: 1.1665 - val_accuracy: 0.5686 - val_precision: 0.8454 - val_recall: 0.2907\n",
            "Epoch 95/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2053 - accuracy: 0.5438 - precision: 0.7412 - recall: 0.3339 - val_loss: 1.1407 - val_accuracy: 0.5649 - val_precision: 0.8040 - val_recall: 0.3365\n",
            "Epoch 96/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2073 - accuracy: 0.5451 - precision: 0.7410 - recall: 0.3411 - val_loss: 1.1421 - val_accuracy: 0.5770 - val_precision: 0.8219 - val_recall: 0.3263\n",
            "Epoch 97/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2041 - accuracy: 0.5448 - precision: 0.7445 - recall: 0.3427 - val_loss: 1.1639 - val_accuracy: 0.5618 - val_precision: 0.8117 - val_recall: 0.3181\n",
            "Epoch 98/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2068 - accuracy: 0.5448 - precision: 0.7410 - recall: 0.3400 - val_loss: 1.1440 - val_accuracy: 0.5671 - val_precision: 0.8082 - val_recall: 0.3338\n",
            "Epoch 99/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2118 - accuracy: 0.5422 - precision: 0.7472 - recall: 0.3404 - val_loss: 1.1465 - val_accuracy: 0.5737 - val_precision: 0.8268 - val_recall: 0.3251\n",
            "Epoch 100/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2055 - accuracy: 0.5425 - precision: 0.7481 - recall: 0.3399 - val_loss: 1.1513 - val_accuracy: 0.5732 - val_precision: 0.8327 - val_recall: 0.3117\n",
            "Epoch 101/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2045 - accuracy: 0.5429 - precision: 0.7446 - recall: 0.3402 - val_loss: 1.1489 - val_accuracy: 0.5654 - val_precision: 0.7960 - val_recall: 0.3401\n",
            "Epoch 102/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2012 - accuracy: 0.5466 - precision: 0.7506 - recall: 0.3455 - val_loss: 1.1487 - val_accuracy: 0.5725 - val_precision: 0.8271 - val_recall: 0.3163\n",
            "Epoch 103/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2053 - accuracy: 0.5412 - precision: 0.7434 - recall: 0.3421 - val_loss: 1.1432 - val_accuracy: 0.5738 - val_precision: 0.8191 - val_recall: 0.3196\n",
            "Epoch 104/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1975 - accuracy: 0.5469 - precision: 0.7470 - recall: 0.3430 - val_loss: 1.1561 - val_accuracy: 0.5652 - val_precision: 0.8178 - val_recall: 0.3138\n",
            "Epoch 105/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2048 - accuracy: 0.5436 - precision: 0.7440 - recall: 0.3408 - val_loss: 1.1597 - val_accuracy: 0.5717 - val_precision: 0.8434 - val_recall: 0.2916\n",
            "Epoch 106/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2046 - accuracy: 0.5451 - precision: 0.7436 - recall: 0.3433 - val_loss: 1.1431 - val_accuracy: 0.5727 - val_precision: 0.8319 - val_recall: 0.3100\n",
            "Epoch 107/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2014 - accuracy: 0.5454 - precision: 0.7486 - recall: 0.3397 - val_loss: 1.1455 - val_accuracy: 0.5632 - val_precision: 0.8068 - val_recall: 0.3258\n",
            "Epoch 108/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2015 - accuracy: 0.5427 - precision: 0.7469 - recall: 0.3412 - val_loss: 1.1622 - val_accuracy: 0.5724 - val_precision: 0.8613 - val_recall: 0.2877\n",
            "Epoch 109/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2002 - accuracy: 0.5481 - precision: 0.7491 - recall: 0.3447 - val_loss: 1.1420 - val_accuracy: 0.5702 - val_precision: 0.8001 - val_recall: 0.3418\n",
            "Epoch 110/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1973 - accuracy: 0.5484 - precision: 0.7476 - recall: 0.3461 - val_loss: 1.1659 - val_accuracy: 0.5649 - val_precision: 0.8292 - val_recall: 0.3027\n",
            "Epoch 111/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1976 - accuracy: 0.5471 - precision: 0.7475 - recall: 0.3445 - val_loss: 1.1401 - val_accuracy: 0.5710 - val_precision: 0.8312 - val_recall: 0.3200\n",
            "Epoch 112/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2044 - accuracy: 0.5461 - precision: 0.7416 - recall: 0.3432 - val_loss: 1.1463 - val_accuracy: 0.5667 - val_precision: 0.8224 - val_recall: 0.3242\n",
            "Epoch 113/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2039 - accuracy: 0.5485 - precision: 0.7430 - recall: 0.3403 - val_loss: 1.1561 - val_accuracy: 0.5699 - val_precision: 0.8522 - val_recall: 0.3008\n",
            "Epoch 114/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2027 - accuracy: 0.5478 - precision: 0.7459 - recall: 0.3402 - val_loss: 1.1464 - val_accuracy: 0.5707 - val_precision: 0.8173 - val_recall: 0.3258\n",
            "Epoch 115/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1988 - accuracy: 0.5475 - precision: 0.7455 - recall: 0.3439 - val_loss: 1.1439 - val_accuracy: 0.5686 - val_precision: 0.8163 - val_recall: 0.3329\n",
            "Epoch 116/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2048 - accuracy: 0.5460 - precision: 0.7412 - recall: 0.3384 - val_loss: 1.1524 - val_accuracy: 0.5650 - val_precision: 0.8282 - val_recall: 0.3094\n",
            "Epoch 117/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2011 - accuracy: 0.5486 - precision: 0.7426 - recall: 0.3465 - val_loss: 1.1390 - val_accuracy: 0.5707 - val_precision: 0.8211 - val_recall: 0.3239\n",
            "Epoch 118/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2116 - accuracy: 0.5410 - precision: 0.7409 - recall: 0.3376 - val_loss: 1.1437 - val_accuracy: 0.5728 - val_precision: 0.8345 - val_recall: 0.3115\n",
            "Epoch 119/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2046 - accuracy: 0.5444 - precision: 0.7432 - recall: 0.3361 - val_loss: 1.1484 - val_accuracy: 0.5695 - val_precision: 0.7965 - val_recall: 0.3298\n",
            "Epoch 120/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1983 - accuracy: 0.5497 - precision: 0.7473 - recall: 0.3456 - val_loss: 1.1323 - val_accuracy: 0.5677 - val_precision: 0.7996 - val_recall: 0.3530\n",
            "Epoch 121/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1985 - accuracy: 0.5485 - precision: 0.7403 - recall: 0.3454 - val_loss: 1.1644 - val_accuracy: 0.5643 - val_precision: 0.8263 - val_recall: 0.3065\n",
            "Epoch 122/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2022 - accuracy: 0.5466 - precision: 0.7426 - recall: 0.3448 - val_loss: 1.1483 - val_accuracy: 0.5705 - val_precision: 0.8254 - val_recall: 0.3105\n",
            "Epoch 123/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1990 - accuracy: 0.5446 - precision: 0.7467 - recall: 0.3408 - val_loss: 1.1501 - val_accuracy: 0.5646 - val_precision: 0.8098 - val_recall: 0.3333\n",
            "Epoch 124/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1957 - accuracy: 0.5517 - precision: 0.7355 - recall: 0.3451 - val_loss: 1.1340 - val_accuracy: 0.5756 - val_precision: 0.8125 - val_recall: 0.3312\n",
            "Epoch 125/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1939 - accuracy: 0.5483 - precision: 0.7419 - recall: 0.3460 - val_loss: 1.1453 - val_accuracy: 0.5626 - val_precision: 0.8153 - val_recall: 0.3160\n",
            "Epoch 126/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1958 - accuracy: 0.5484 - precision: 0.7440 - recall: 0.3460 - val_loss: 1.1424 - val_accuracy: 0.5724 - val_precision: 0.8256 - val_recall: 0.3184\n",
            "Epoch 127/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1976 - accuracy: 0.5487 - precision: 0.7484 - recall: 0.3472 - val_loss: 1.1418 - val_accuracy: 0.5751 - val_precision: 0.8125 - val_recall: 0.3228\n",
            "Epoch 128/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2001 - accuracy: 0.5477 - precision: 0.7388 - recall: 0.3435 - val_loss: 1.1429 - val_accuracy: 0.5709 - val_precision: 0.8160 - val_recall: 0.3230\n",
            "Epoch 129/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1985 - accuracy: 0.5469 - precision: 0.7480 - recall: 0.3427 - val_loss: 1.1374 - val_accuracy: 0.5677 - val_precision: 0.7946 - val_recall: 0.3503\n",
            "Epoch 130/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1926 - accuracy: 0.5508 - precision: 0.7444 - recall: 0.3463 - val_loss: 1.1474 - val_accuracy: 0.5709 - val_precision: 0.8367 - val_recall: 0.3181\n",
            "Epoch 131/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1960 - accuracy: 0.5509 - precision: 0.7423 - recall: 0.3449 - val_loss: 1.1572 - val_accuracy: 0.5601 - val_precision: 0.8106 - val_recall: 0.3218\n",
            "Epoch 132/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1995 - accuracy: 0.5468 - precision: 0.7456 - recall: 0.3445 - val_loss: 1.1433 - val_accuracy: 0.5724 - val_precision: 0.8263 - val_recall: 0.3225\n",
            "Epoch 133/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1932 - accuracy: 0.5511 - precision: 0.7424 - recall: 0.3455 - val_loss: 1.1402 - val_accuracy: 0.5721 - val_precision: 0.8229 - val_recall: 0.3287\n",
            "Epoch 134/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1912 - accuracy: 0.5489 - precision: 0.7409 - recall: 0.3467 - val_loss: 1.1544 - val_accuracy: 0.5663 - val_precision: 0.8182 - val_recall: 0.3265\n",
            "Epoch 135/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1905 - accuracy: 0.5479 - precision: 0.7464 - recall: 0.3497 - val_loss: 1.1440 - val_accuracy: 0.5787 - val_precision: 0.8203 - val_recall: 0.3184\n",
            "Epoch 136/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.2024 - accuracy: 0.5480 - precision: 0.7449 - recall: 0.3425 - val_loss: 1.1520 - val_accuracy: 0.5705 - val_precision: 0.8237 - val_recall: 0.3129\n",
            "Epoch 137/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1936 - accuracy: 0.5482 - precision: 0.7455 - recall: 0.3442 - val_loss: 1.1601 - val_accuracy: 0.5654 - val_precision: 0.8197 - val_recall: 0.3089\n",
            "Epoch 138/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1926 - accuracy: 0.5499 - precision: 0.7436 - recall: 0.3487 - val_loss: 1.1536 - val_accuracy: 0.5652 - val_precision: 0.8341 - val_recall: 0.3163\n",
            "Epoch 139/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1959 - accuracy: 0.5466 - precision: 0.7461 - recall: 0.3442 - val_loss: 1.1544 - val_accuracy: 0.5705 - val_precision: 0.8291 - val_recall: 0.3045\n",
            "Epoch 140/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1942 - accuracy: 0.5475 - precision: 0.7412 - recall: 0.3449 - val_loss: 1.1385 - val_accuracy: 0.5693 - val_precision: 0.8069 - val_recall: 0.3316\n",
            "Epoch 141/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1925 - accuracy: 0.5490 - precision: 0.7432 - recall: 0.3451 - val_loss: 1.1455 - val_accuracy: 0.5742 - val_precision: 0.8370 - val_recall: 0.2995\n",
            "Epoch 142/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1909 - accuracy: 0.5490 - precision: 0.7484 - recall: 0.3441 - val_loss: 1.1376 - val_accuracy: 0.5670 - val_precision: 0.8053 - val_recall: 0.3398\n",
            "Epoch 143/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1888 - accuracy: 0.5512 - precision: 0.7447 - recall: 0.3520 - val_loss: 1.1427 - val_accuracy: 0.5674 - val_precision: 0.8199 - val_recall: 0.3295\n",
            "Epoch 144/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1883 - accuracy: 0.5547 - precision: 0.7448 - recall: 0.3508 - val_loss: 1.1550 - val_accuracy: 0.5665 - val_precision: 0.8128 - val_recall: 0.3186\n",
            "Epoch 145/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1913 - accuracy: 0.5530 - precision: 0.7458 - recall: 0.3483 - val_loss: 1.1404 - val_accuracy: 0.5664 - val_precision: 0.8026 - val_recall: 0.3306\n",
            "Epoch 146/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1949 - accuracy: 0.5501 - precision: 0.7435 - recall: 0.3489 - val_loss: 1.1398 - val_accuracy: 0.5696 - val_precision: 0.8025 - val_recall: 0.3470\n",
            "Epoch 147/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1854 - accuracy: 0.5521 - precision: 0.7492 - recall: 0.3533 - val_loss: 1.1331 - val_accuracy: 0.5734 - val_precision: 0.8211 - val_recall: 0.3246\n",
            "Epoch 148/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1841 - accuracy: 0.5543 - precision: 0.7445 - recall: 0.3576 - val_loss: 1.1505 - val_accuracy: 0.5703 - val_precision: 0.8457 - val_recall: 0.2997\n",
            "Epoch 149/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1838 - accuracy: 0.5497 - precision: 0.7435 - recall: 0.3506 - val_loss: 1.1422 - val_accuracy: 0.5612 - val_precision: 0.7963 - val_recall: 0.3359\n",
            "Epoch 150/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1875 - accuracy: 0.5504 - precision: 0.7474 - recall: 0.3500 - val_loss: 1.1463 - val_accuracy: 0.5720 - val_precision: 0.7967 - val_recall: 0.3368\n",
            "Epoch 151/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1895 - accuracy: 0.5526 - precision: 0.7447 - recall: 0.3513 - val_loss: 1.1367 - val_accuracy: 0.5728 - val_precision: 0.8161 - val_recall: 0.3375\n",
            "Epoch 152/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1891 - accuracy: 0.5523 - precision: 0.7456 - recall: 0.3511 - val_loss: 1.1299 - val_accuracy: 0.5716 - val_precision: 0.8278 - val_recall: 0.3245\n",
            "Epoch 153/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1897 - accuracy: 0.5514 - precision: 0.7439 - recall: 0.3525 - val_loss: 1.1365 - val_accuracy: 0.5724 - val_precision: 0.8367 - val_recall: 0.3174\n",
            "Epoch 154/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1820 - accuracy: 0.5543 - precision: 0.7492 - recall: 0.3533 - val_loss: 1.1510 - val_accuracy: 0.5705 - val_precision: 0.8300 - val_recall: 0.3216\n",
            "Epoch 155/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1873 - accuracy: 0.5535 - precision: 0.7449 - recall: 0.3518 - val_loss: 1.1236 - val_accuracy: 0.5746 - val_precision: 0.8145 - val_recall: 0.3369\n",
            "Epoch 156/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1855 - accuracy: 0.5513 - precision: 0.7429 - recall: 0.3533 - val_loss: 1.1468 - val_accuracy: 0.5732 - val_precision: 0.8475 - val_recall: 0.3032\n",
            "Epoch 157/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1862 - accuracy: 0.5546 - precision: 0.7445 - recall: 0.3485 - val_loss: 1.1527 - val_accuracy: 0.5650 - val_precision: 0.8233 - val_recall: 0.3062\n",
            "Epoch 158/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1850 - accuracy: 0.5546 - precision: 0.7459 - recall: 0.3541 - val_loss: 1.1421 - val_accuracy: 0.5699 - val_precision: 0.8251 - val_recall: 0.3165\n",
            "Epoch 159/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1864 - accuracy: 0.5516 - precision: 0.7475 - recall: 0.3508 - val_loss: 1.1500 - val_accuracy: 0.5728 - val_precision: 0.8178 - val_recall: 0.3156\n",
            "Epoch 160/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1835 - accuracy: 0.5528 - precision: 0.7450 - recall: 0.3538 - val_loss: 1.1368 - val_accuracy: 0.5760 - val_precision: 0.8191 - val_recall: 0.3271\n",
            "Epoch 161/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1794 - accuracy: 0.5565 - precision: 0.7454 - recall: 0.3603 - val_loss: 1.1314 - val_accuracy: 0.5698 - val_precision: 0.8127 - val_recall: 0.3415\n",
            "Epoch 162/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1894 - accuracy: 0.5535 - precision: 0.7490 - recall: 0.3547 - val_loss: 1.1334 - val_accuracy: 0.5744 - val_precision: 0.8083 - val_recall: 0.3376\n",
            "Epoch 163/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1825 - accuracy: 0.5563 - precision: 0.7449 - recall: 0.3559 - val_loss: 1.1365 - val_accuracy: 0.5730 - val_precision: 0.8163 - val_recall: 0.3298\n",
            "Epoch 164/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1776 - accuracy: 0.5551 - precision: 0.7452 - recall: 0.3563 - val_loss: 1.1436 - val_accuracy: 0.5802 - val_precision: 0.8208 - val_recall: 0.3239\n",
            "Epoch 165/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1888 - accuracy: 0.5537 - precision: 0.7455 - recall: 0.3516 - val_loss: 1.1322 - val_accuracy: 0.5770 - val_precision: 0.8266 - val_recall: 0.3259\n",
            "Epoch 166/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1790 - accuracy: 0.5531 - precision: 0.7495 - recall: 0.3555 - val_loss: 1.1335 - val_accuracy: 0.5727 - val_precision: 0.7887 - val_recall: 0.3394\n",
            "Epoch 167/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1928 - accuracy: 0.5549 - precision: 0.7476 - recall: 0.3528 - val_loss: 1.1310 - val_accuracy: 0.5731 - val_precision: 0.7992 - val_recall: 0.3475\n",
            "Epoch 168/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1782 - accuracy: 0.5561 - precision: 0.7492 - recall: 0.3558 - val_loss: 1.1322 - val_accuracy: 0.5696 - val_precision: 0.7983 - val_recall: 0.3446\n",
            "Epoch 169/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1846 - accuracy: 0.5538 - precision: 0.7490 - recall: 0.3546 - val_loss: 1.1494 - val_accuracy: 0.5710 - val_precision: 0.7996 - val_recall: 0.3390\n",
            "Epoch 170/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1868 - accuracy: 0.5540 - precision: 0.7505 - recall: 0.3535 - val_loss: 1.1495 - val_accuracy: 0.5677 - val_precision: 0.7997 - val_recall: 0.3380\n",
            "Epoch 171/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1801 - accuracy: 0.5536 - precision: 0.7484 - recall: 0.3548 - val_loss: 1.1266 - val_accuracy: 0.5790 - val_precision: 0.8348 - val_recall: 0.3285\n",
            "Epoch 172/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1849 - accuracy: 0.5522 - precision: 0.7491 - recall: 0.3515 - val_loss: 1.1230 - val_accuracy: 0.5774 - val_precision: 0.8233 - val_recall: 0.3302\n",
            "Epoch 173/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1785 - accuracy: 0.5560 - precision: 0.7506 - recall: 0.3536 - val_loss: 1.1226 - val_accuracy: 0.5739 - val_precision: 0.8097 - val_recall: 0.3460\n",
            "Epoch 174/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1777 - accuracy: 0.5562 - precision: 0.7503 - recall: 0.3547 - val_loss: 1.1294 - val_accuracy: 0.5713 - val_precision: 0.8035 - val_recall: 0.3361\n",
            "Epoch 175/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1881 - accuracy: 0.5544 - precision: 0.7417 - recall: 0.3508 - val_loss: 1.1345 - val_accuracy: 0.5668 - val_precision: 0.8269 - val_recall: 0.3185\n",
            "Epoch 176/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1793 - accuracy: 0.5550 - precision: 0.7505 - recall: 0.3554 - val_loss: 1.1411 - val_accuracy: 0.5663 - val_precision: 0.7997 - val_recall: 0.3493\n",
            "Epoch 177/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1794 - accuracy: 0.5566 - precision: 0.7479 - recall: 0.3599 - val_loss: 1.1415 - val_accuracy: 0.5693 - val_precision: 0.8065 - val_recall: 0.3344\n",
            "Epoch 178/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1758 - accuracy: 0.5550 - precision: 0.7525 - recall: 0.3553 - val_loss: 1.1144 - val_accuracy: 0.5784 - val_precision: 0.8106 - val_recall: 0.3492\n",
            "Epoch 179/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1819 - accuracy: 0.5543 - precision: 0.7429 - recall: 0.3545 - val_loss: 1.1303 - val_accuracy: 0.5784 - val_precision: 0.8313 - val_recall: 0.3273\n",
            "Epoch 180/400\n",
            "897/897 [==============================] - 27s 30ms/step - loss: 1.1884 - accuracy: 0.5539 - precision: 0.7502 - recall: 0.3538 - val_loss: 1.1247 - val_accuracy: 0.5857 - val_precision: 0.8234 - val_recall: 0.3351\n",
            "Epoch 181/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1777 - accuracy: 0.5550 - precision: 0.7479 - recall: 0.3578 - val_loss: 1.1290 - val_accuracy: 0.5797 - val_precision: 0.8204 - val_recall: 0.3306\n",
            "Epoch 182/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1827 - accuracy: 0.5551 - precision: 0.7458 - recall: 0.3529 - val_loss: 1.1271 - val_accuracy: 0.5799 - val_precision: 0.8314 - val_recall: 0.3239\n",
            "Epoch 183/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1781 - accuracy: 0.5559 - precision: 0.7483 - recall: 0.3523 - val_loss: 1.1321 - val_accuracy: 0.5751 - val_precision: 0.7954 - val_recall: 0.3405\n",
            "Epoch 184/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1741 - accuracy: 0.5594 - precision: 0.7492 - recall: 0.3622 - val_loss: 1.1359 - val_accuracy: 0.5741 - val_precision: 0.8121 - val_recall: 0.3316\n",
            "Epoch 185/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1786 - accuracy: 0.5574 - precision: 0.7474 - recall: 0.3607 - val_loss: 1.1422 - val_accuracy: 0.5670 - val_precision: 0.8181 - val_recall: 0.3401\n",
            "Epoch 186/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1821 - accuracy: 0.5584 - precision: 0.7441 - recall: 0.3573 - val_loss: 1.1464 - val_accuracy: 0.5720 - val_precision: 0.8289 - val_recall: 0.3157\n",
            "Epoch 187/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1765 - accuracy: 0.5536 - precision: 0.7486 - recall: 0.3558 - val_loss: 1.1354 - val_accuracy: 0.5778 - val_precision: 0.8195 - val_recall: 0.3193\n",
            "Epoch 188/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1787 - accuracy: 0.5570 - precision: 0.7458 - recall: 0.3596 - val_loss: 1.1121 - val_accuracy: 0.5827 - val_precision: 0.8227 - val_recall: 0.3313\n",
            "Epoch 189/400\n",
            "897/897 [==============================] - 27s 30ms/step - loss: 1.1769 - accuracy: 0.5582 - precision: 0.7445 - recall: 0.3577 - val_loss: 1.1241 - val_accuracy: 0.5787 - val_precision: 0.8126 - val_recall: 0.3454\n",
            "Epoch 190/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1787 - accuracy: 0.5567 - precision: 0.7472 - recall: 0.3585 - val_loss: 1.1237 - val_accuracy: 0.5795 - val_precision: 0.8016 - val_recall: 0.3433\n",
            "Epoch 191/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1759 - accuracy: 0.5592 - precision: 0.7438 - recall: 0.3592 - val_loss: 1.1575 - val_accuracy: 0.5699 - val_precision: 0.8365 - val_recall: 0.3033\n",
            "Epoch 192/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1685 - accuracy: 0.5587 - precision: 0.7488 - recall: 0.3637 - val_loss: 1.1340 - val_accuracy: 0.5738 - val_precision: 0.8001 - val_recall: 0.3439\n",
            "Epoch 193/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1734 - accuracy: 0.5555 - precision: 0.7443 - recall: 0.3614 - val_loss: 1.1261 - val_accuracy: 0.5744 - val_precision: 0.8158 - val_recall: 0.3350\n",
            "Epoch 194/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1824 - accuracy: 0.5527 - precision: 0.7477 - recall: 0.3542 - val_loss: 1.1369 - val_accuracy: 0.5776 - val_precision: 0.8233 - val_recall: 0.3249\n",
            "Epoch 195/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1744 - accuracy: 0.5574 - precision: 0.7497 - recall: 0.3591 - val_loss: 1.1373 - val_accuracy: 0.5660 - val_precision: 0.7788 - val_recall: 0.3644\n",
            "Epoch 196/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1828 - accuracy: 0.5587 - precision: 0.7479 - recall: 0.3574 - val_loss: 1.1117 - val_accuracy: 0.5788 - val_precision: 0.8045 - val_recall: 0.3588\n",
            "Epoch 197/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1714 - accuracy: 0.5585 - precision: 0.7471 - recall: 0.3651 - val_loss: 1.1633 - val_accuracy: 0.5711 - val_precision: 0.8272 - val_recall: 0.2945\n",
            "Epoch 198/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1621 - accuracy: 0.5583 - precision: 0.7499 - recall: 0.3661 - val_loss: 1.1424 - val_accuracy: 0.5716 - val_precision: 0.8338 - val_recall: 0.3205\n",
            "Epoch 199/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1716 - accuracy: 0.5618 - precision: 0.7516 - recall: 0.3652 - val_loss: 1.1250 - val_accuracy: 0.5799 - val_precision: 0.8076 - val_recall: 0.3472\n",
            "Epoch 200/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1711 - accuracy: 0.5599 - precision: 0.7482 - recall: 0.3625 - val_loss: 1.1082 - val_accuracy: 0.5815 - val_precision: 0.8008 - val_recall: 0.3534\n",
            "Epoch 201/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1689 - accuracy: 0.5612 - precision: 0.7515 - recall: 0.3687 - val_loss: 1.1314 - val_accuracy: 0.5682 - val_precision: 0.8289 - val_recall: 0.3170\n",
            "Epoch 202/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1740 - accuracy: 0.5565 - precision: 0.7463 - recall: 0.3626 - val_loss: 1.1286 - val_accuracy: 0.5702 - val_precision: 0.7955 - val_recall: 0.3566\n",
            "Epoch 203/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1731 - accuracy: 0.5593 - precision: 0.7490 - recall: 0.3637 - val_loss: 1.1058 - val_accuracy: 0.5812 - val_precision: 0.8043 - val_recall: 0.3562\n",
            "Epoch 204/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1682 - accuracy: 0.5624 - precision: 0.7503 - recall: 0.3647 - val_loss: 1.1274 - val_accuracy: 0.5661 - val_precision: 0.8009 - val_recall: 0.3338\n",
            "Epoch 205/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1745 - accuracy: 0.5582 - precision: 0.7455 - recall: 0.3614 - val_loss: 1.1352 - val_accuracy: 0.5665 - val_precision: 0.8044 - val_recall: 0.3443\n",
            "Epoch 206/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1751 - accuracy: 0.5575 - precision: 0.7476 - recall: 0.3596 - val_loss: 1.1354 - val_accuracy: 0.5751 - val_precision: 0.7982 - val_recall: 0.3389\n",
            "Epoch 207/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1702 - accuracy: 0.5606 - precision: 0.7536 - recall: 0.3625 - val_loss: 1.1190 - val_accuracy: 0.5664 - val_precision: 0.7838 - val_recall: 0.3668\n",
            "Epoch 208/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1747 - accuracy: 0.5595 - precision: 0.7435 - recall: 0.3607 - val_loss: 1.1187 - val_accuracy: 0.5752 - val_precision: 0.8164 - val_recall: 0.3418\n",
            "Epoch 209/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1728 - accuracy: 0.5619 - precision: 0.7494 - recall: 0.3645 - val_loss: 1.1263 - val_accuracy: 0.5744 - val_precision: 0.8024 - val_recall: 0.3592\n",
            "Epoch 210/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1710 - accuracy: 0.5581 - precision: 0.7475 - recall: 0.3636 - val_loss: 1.1307 - val_accuracy: 0.5763 - val_precision: 0.8184 - val_recall: 0.3269\n",
            "Epoch 211/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1697 - accuracy: 0.5562 - precision: 0.7517 - recall: 0.3633 - val_loss: 1.1421 - val_accuracy: 0.5728 - val_precision: 0.8294 - val_recall: 0.3160\n",
            "Epoch 212/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1659 - accuracy: 0.5612 - precision: 0.7535 - recall: 0.3662 - val_loss: 1.1270 - val_accuracy: 0.5801 - val_precision: 0.8240 - val_recall: 0.3273\n",
            "Epoch 213/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1695 - accuracy: 0.5586 - precision: 0.7470 - recall: 0.3631 - val_loss: 1.1187 - val_accuracy: 0.5725 - val_precision: 0.7988 - val_recall: 0.3612\n",
            "Epoch 214/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1766 - accuracy: 0.5563 - precision: 0.7464 - recall: 0.3599 - val_loss: 1.1331 - val_accuracy: 0.5725 - val_precision: 0.8204 - val_recall: 0.3269\n",
            "Epoch 215/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1667 - accuracy: 0.5615 - precision: 0.7496 - recall: 0.3658 - val_loss: 1.1268 - val_accuracy: 0.5780 - val_precision: 0.8116 - val_recall: 0.3384\n",
            "Epoch 216/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1685 - accuracy: 0.5606 - precision: 0.7493 - recall: 0.3633 - val_loss: 1.1513 - val_accuracy: 0.5784 - val_precision: 0.8158 - val_recall: 0.3163\n",
            "Epoch 217/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1717 - accuracy: 0.5563 - precision: 0.7452 - recall: 0.3623 - val_loss: 1.1180 - val_accuracy: 0.5818 - val_precision: 0.8242 - val_recall: 0.3414\n",
            "Epoch 218/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1709 - accuracy: 0.5610 - precision: 0.7465 - recall: 0.3630 - val_loss: 1.1438 - val_accuracy: 0.5748 - val_precision: 0.8128 - val_recall: 0.3126\n",
            "Epoch 219/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1711 - accuracy: 0.5583 - precision: 0.7473 - recall: 0.3583 - val_loss: 1.1289 - val_accuracy: 0.5698 - val_precision: 0.8108 - val_recall: 0.3384\n",
            "Epoch 220/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1718 - accuracy: 0.5569 - precision: 0.7427 - recall: 0.3599 - val_loss: 1.1254 - val_accuracy: 0.5806 - val_precision: 0.8254 - val_recall: 0.3331\n",
            "Epoch 221/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1716 - accuracy: 0.5582 - precision: 0.7477 - recall: 0.3588 - val_loss: 1.1330 - val_accuracy: 0.5745 - val_precision: 0.8163 - val_recall: 0.3341\n",
            "Epoch 222/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1691 - accuracy: 0.5610 - precision: 0.7491 - recall: 0.3646 - val_loss: 1.1344 - val_accuracy: 0.5790 - val_precision: 0.8320 - val_recall: 0.3199\n",
            "Epoch 223/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1688 - accuracy: 0.5586 - precision: 0.7458 - recall: 0.3652 - val_loss: 1.1411 - val_accuracy: 0.5749 - val_precision: 0.8319 - val_recall: 0.3065\n",
            "Epoch 224/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1678 - accuracy: 0.5581 - precision: 0.7467 - recall: 0.3657 - val_loss: 1.1099 - val_accuracy: 0.5771 - val_precision: 0.8034 - val_recall: 0.3677\n",
            "Epoch 225/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1622 - accuracy: 0.5619 - precision: 0.7482 - recall: 0.3644 - val_loss: 1.1283 - val_accuracy: 0.5797 - val_precision: 0.8073 - val_recall: 0.3354\n",
            "Epoch 226/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1604 - accuracy: 0.5640 - precision: 0.7498 - recall: 0.3714 - val_loss: 1.1099 - val_accuracy: 0.5787 - val_precision: 0.7663 - val_recall: 0.3782\n",
            "Epoch 227/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1676 - accuracy: 0.5599 - precision: 0.7478 - recall: 0.3673 - val_loss: 1.1123 - val_accuracy: 0.5822 - val_precision: 0.7915 - val_recall: 0.3627\n",
            "Epoch 228/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1599 - accuracy: 0.5636 - precision: 0.7484 - recall: 0.3663 - val_loss: 1.1288 - val_accuracy: 0.5805 - val_precision: 0.8314 - val_recall: 0.3269\n",
            "Epoch 229/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1642 - accuracy: 0.5620 - precision: 0.7495 - recall: 0.3619 - val_loss: 1.1513 - val_accuracy: 0.5681 - val_precision: 0.8366 - val_recall: 0.3072\n",
            "Epoch 230/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1661 - accuracy: 0.5599 - precision: 0.7473 - recall: 0.3616 - val_loss: 1.1287 - val_accuracy: 0.5746 - val_precision: 0.8107 - val_recall: 0.3371\n",
            "Epoch 231/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1710 - accuracy: 0.5618 - precision: 0.7501 - recall: 0.3625 - val_loss: 1.1150 - val_accuracy: 0.5812 - val_precision: 0.8155 - val_recall: 0.3557\n",
            "Epoch 232/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1715 - accuracy: 0.5601 - precision: 0.7475 - recall: 0.3611 - val_loss: 1.1481 - val_accuracy: 0.5749 - val_precision: 0.8157 - val_recall: 0.3241\n",
            "Epoch 233/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1637 - accuracy: 0.5607 - precision: 0.7461 - recall: 0.3631 - val_loss: 1.1255 - val_accuracy: 0.5776 - val_precision: 0.8307 - val_recall: 0.3326\n",
            "Epoch 234/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1693 - accuracy: 0.5617 - precision: 0.7506 - recall: 0.3628 - val_loss: 1.1374 - val_accuracy: 0.5713 - val_precision: 0.8131 - val_recall: 0.3351\n",
            "Epoch 235/400\n",
            "897/897 [==============================] - 27s 30ms/step - loss: 1.1687 - accuracy: 0.5585 - precision: 0.7459 - recall: 0.3645 - val_loss: 1.1379 - val_accuracy: 0.5785 - val_precision: 0.8268 - val_recall: 0.3097\n",
            "Epoch 236/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1669 - accuracy: 0.5661 - precision: 0.7494 - recall: 0.3644 - val_loss: 1.1150 - val_accuracy: 0.5784 - val_precision: 0.8100 - val_recall: 0.3485\n",
            "Epoch 237/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1714 - accuracy: 0.5592 - precision: 0.7506 - recall: 0.3634 - val_loss: 1.1166 - val_accuracy: 0.5806 - val_precision: 0.8268 - val_recall: 0.3403\n",
            "Epoch 238/400\n",
            "897/897 [==============================] - 27s 30ms/step - loss: 1.1683 - accuracy: 0.5634 - precision: 0.7433 - recall: 0.3663 - val_loss: 1.1231 - val_accuracy: 0.5763 - val_precision: 0.8130 - val_recall: 0.3414\n",
            "Epoch 239/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1653 - accuracy: 0.5604 - precision: 0.7458 - recall: 0.3648 - val_loss: 1.1523 - val_accuracy: 0.5682 - val_precision: 0.8077 - val_recall: 0.3177\n",
            "Epoch 240/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1666 - accuracy: 0.5586 - precision: 0.7501 - recall: 0.3626 - val_loss: 1.1332 - val_accuracy: 0.5705 - val_precision: 0.7926 - val_recall: 0.3592\n",
            "Epoch 241/400\n",
            "897/897 [==============================] - 26s 30ms/step - loss: 1.1694 - accuracy: 0.5554 - precision: 0.7465 - recall: 0.3600 - val_loss: 1.1214 - val_accuracy: 0.5760 - val_precision: 0.8032 - val_recall: 0.3428\n",
            "Epoch 242/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1697 - accuracy: 0.5595 - precision: 0.7516 - recall: 0.3628 - val_loss: 1.1329 - val_accuracy: 0.5777 - val_precision: 0.8246 - val_recall: 0.3259\n",
            "Epoch 243/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1650 - accuracy: 0.5622 - precision: 0.7491 - recall: 0.3647 - val_loss: 1.1109 - val_accuracy: 0.5790 - val_precision: 0.8080 - val_recall: 0.3504\n",
            "Epoch 244/400\n",
            "897/897 [==============================] - 26s 30ms/step - loss: 1.1631 - accuracy: 0.5616 - precision: 0.7505 - recall: 0.3689 - val_loss: 1.1097 - val_accuracy: 0.5815 - val_precision: 0.7992 - val_recall: 0.3609\n",
            "Epoch 245/400\n",
            "897/897 [==============================] - 27s 30ms/step - loss: 1.1689 - accuracy: 0.5583 - precision: 0.7488 - recall: 0.3628 - val_loss: 1.1258 - val_accuracy: 0.5756 - val_precision: 0.8218 - val_recall: 0.3333\n",
            "Epoch 246/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1643 - accuracy: 0.5615 - precision: 0.7494 - recall: 0.3657 - val_loss: 1.1384 - val_accuracy: 0.5861 - val_precision: 0.8160 - val_recall: 0.3253\n",
            "Epoch 247/400\n",
            "897/897 [==============================] - 26s 30ms/step - loss: 1.1623 - accuracy: 0.5613 - precision: 0.7514 - recall: 0.3666 - val_loss: 1.1135 - val_accuracy: 0.5801 - val_precision: 0.8234 - val_recall: 0.3344\n",
            "Epoch 248/400\n",
            "897/897 [==============================] - 27s 30ms/step - loss: 1.1495 - accuracy: 0.5691 - precision: 0.7518 - recall: 0.3751 - val_loss: 1.1298 - val_accuracy: 0.5802 - val_precision: 0.8194 - val_recall: 0.3298\n",
            "Epoch 249/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1703 - accuracy: 0.5591 - precision: 0.7482 - recall: 0.3641 - val_loss: 1.1397 - val_accuracy: 0.5710 - val_precision: 0.8261 - val_recall: 0.3195\n",
            "Epoch 250/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1649 - accuracy: 0.5603 - precision: 0.7464 - recall: 0.3638 - val_loss: 1.1134 - val_accuracy: 0.5802 - val_precision: 0.8059 - val_recall: 0.3539\n",
            "Epoch 251/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1608 - accuracy: 0.5626 - precision: 0.7467 - recall: 0.3687 - val_loss: 1.1268 - val_accuracy: 0.5753 - val_precision: 0.8057 - val_recall: 0.3499\n",
            "Epoch 252/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1677 - accuracy: 0.5639 - precision: 0.7513 - recall: 0.3639 - val_loss: 1.1430 - val_accuracy: 0.5718 - val_precision: 0.8145 - val_recall: 0.3266\n",
            "Epoch 253/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1639 - accuracy: 0.5630 - precision: 0.7497 - recall: 0.3677 - val_loss: 1.1248 - val_accuracy: 0.5771 - val_precision: 0.7903 - val_recall: 0.3606\n",
            "Epoch 254/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1602 - accuracy: 0.5641 - precision: 0.7448 - recall: 0.3706 - val_loss: 1.1266 - val_accuracy: 0.5749 - val_precision: 0.8004 - val_recall: 0.3509\n",
            "Epoch 255/400\n",
            "897/897 [==============================] - 27s 30ms/step - loss: 1.1582 - accuracy: 0.5647 - precision: 0.7548 - recall: 0.3741 - val_loss: 1.1165 - val_accuracy: 0.5746 - val_precision: 0.8156 - val_recall: 0.3382\n",
            "Epoch 256/400\n",
            "897/897 [==============================] - 27s 30ms/step - loss: 1.1591 - accuracy: 0.5655 - precision: 0.7530 - recall: 0.3732 - val_loss: 1.1182 - val_accuracy: 0.5771 - val_precision: 0.7993 - val_recall: 0.3534\n",
            "Epoch 257/400\n",
            "897/897 [==============================] - 27s 30ms/step - loss: 1.1671 - accuracy: 0.5608 - precision: 0.7482 - recall: 0.3607 - val_loss: 1.1586 - val_accuracy: 0.5633 - val_precision: 0.8153 - val_recall: 0.3153\n",
            "Epoch 258/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1626 - accuracy: 0.5665 - precision: 0.7470 - recall: 0.3685 - val_loss: 1.1084 - val_accuracy: 0.5790 - val_precision: 0.8030 - val_recall: 0.3610\n",
            "Epoch 259/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1570 - accuracy: 0.5633 - precision: 0.7479 - recall: 0.3711 - val_loss: 1.1162 - val_accuracy: 0.5785 - val_precision: 0.8269 - val_recall: 0.3299\n",
            "Epoch 260/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1611 - accuracy: 0.5622 - precision: 0.7506 - recall: 0.3675 - val_loss: 1.1233 - val_accuracy: 0.5766 - val_precision: 0.8200 - val_recall: 0.3357\n",
            "Epoch 261/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1658 - accuracy: 0.5615 - precision: 0.7472 - recall: 0.3656 - val_loss: 1.1142 - val_accuracy: 0.5746 - val_precision: 0.8088 - val_recall: 0.3570\n",
            "Epoch 262/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1546 - accuracy: 0.5650 - precision: 0.7500 - recall: 0.3730 - val_loss: 1.1249 - val_accuracy: 0.5737 - val_precision: 0.7932 - val_recall: 0.3693\n",
            "Epoch 263/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1636 - accuracy: 0.5613 - precision: 0.7528 - recall: 0.3694 - val_loss: 1.1233 - val_accuracy: 0.5698 - val_precision: 0.8200 - val_recall: 0.3344\n",
            "Epoch 264/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1571 - accuracy: 0.5636 - precision: 0.7533 - recall: 0.3673 - val_loss: 1.1050 - val_accuracy: 0.5774 - val_precision: 0.8128 - val_recall: 0.3598\n",
            "Epoch 265/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1613 - accuracy: 0.5668 - precision: 0.7490 - recall: 0.3692 - val_loss: 1.1235 - val_accuracy: 0.5758 - val_precision: 0.8146 - val_recall: 0.3415\n",
            "Epoch 266/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1654 - accuracy: 0.5619 - precision: 0.7497 - recall: 0.3676 - val_loss: 1.1338 - val_accuracy: 0.5735 - val_precision: 0.8202 - val_recall: 0.3304\n",
            "Epoch 267/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1605 - accuracy: 0.5626 - precision: 0.7478 - recall: 0.3679 - val_loss: 1.1124 - val_accuracy: 0.5804 - val_precision: 0.7987 - val_recall: 0.3686\n",
            "Epoch 268/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1505 - accuracy: 0.5686 - precision: 0.7525 - recall: 0.3761 - val_loss: 1.1185 - val_accuracy: 0.5785 - val_precision: 0.8329 - val_recall: 0.3422\n",
            "Epoch 269/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1597 - accuracy: 0.5628 - precision: 0.7519 - recall: 0.3703 - val_loss: 1.1318 - val_accuracy: 0.5785 - val_precision: 0.8163 - val_recall: 0.3391\n",
            "Epoch 270/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1538 - accuracy: 0.5642 - precision: 0.7495 - recall: 0.3743 - val_loss: 1.1345 - val_accuracy: 0.5688 - val_precision: 0.8184 - val_recall: 0.3288\n",
            "Epoch 271/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1560 - accuracy: 0.5655 - precision: 0.7516 - recall: 0.3723 - val_loss: 1.1341 - val_accuracy: 0.5748 - val_precision: 0.8255 - val_recall: 0.3320\n",
            "Epoch 272/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1625 - accuracy: 0.5619 - precision: 0.7532 - recall: 0.3683 - val_loss: 1.1291 - val_accuracy: 0.5737 - val_precision: 0.8140 - val_recall: 0.3401\n",
            "Epoch 273/400\n",
            "897/897 [==============================] - 27s 30ms/step - loss: 1.1569 - accuracy: 0.5653 - precision: 0.7473 - recall: 0.3721 - val_loss: 1.1329 - val_accuracy: 0.5766 - val_precision: 0.8213 - val_recall: 0.3329\n",
            "Epoch 274/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1673 - accuracy: 0.5617 - precision: 0.7524 - recall: 0.3655 - val_loss: 1.1097 - val_accuracy: 0.5855 - val_precision: 0.7934 - val_recall: 0.3729\n",
            "Epoch 275/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1648 - accuracy: 0.5614 - precision: 0.7514 - recall: 0.3671 - val_loss: 1.1476 - val_accuracy: 0.5716 - val_precision: 0.8268 - val_recall: 0.3129\n",
            "Epoch 276/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1595 - accuracy: 0.5619 - precision: 0.7514 - recall: 0.3683 - val_loss: 1.1216 - val_accuracy: 0.5809 - val_precision: 0.8111 - val_recall: 0.3463\n",
            "Epoch 277/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1614 - accuracy: 0.5652 - precision: 0.7515 - recall: 0.3692 - val_loss: 1.1096 - val_accuracy: 0.5791 - val_precision: 0.8021 - val_recall: 0.3574\n",
            "Epoch 278/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1557 - accuracy: 0.5631 - precision: 0.7510 - recall: 0.3728 - val_loss: 1.1141 - val_accuracy: 0.5774 - val_precision: 0.8197 - val_recall: 0.3431\n",
            "Epoch 279/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1549 - accuracy: 0.5635 - precision: 0.7493 - recall: 0.3705 - val_loss: 1.1326 - val_accuracy: 0.5631 - val_precision: 0.8046 - val_recall: 0.3493\n",
            "Epoch 280/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1630 - accuracy: 0.5610 - precision: 0.7543 - recall: 0.3679 - val_loss: 1.1266 - val_accuracy: 0.5808 - val_precision: 0.8410 - val_recall: 0.3210\n",
            "Epoch 281/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1633 - accuracy: 0.5631 - precision: 0.7487 - recall: 0.3665 - val_loss: 1.1377 - val_accuracy: 0.5787 - val_precision: 0.8408 - val_recall: 0.3175\n",
            "Epoch 282/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1561 - accuracy: 0.5663 - precision: 0.7520 - recall: 0.3678 - val_loss: 1.1091 - val_accuracy: 0.5818 - val_precision: 0.7952 - val_recall: 0.3677\n",
            "Epoch 283/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1586 - accuracy: 0.5650 - precision: 0.7490 - recall: 0.3695 - val_loss: 1.1181 - val_accuracy: 0.5857 - val_precision: 0.8208 - val_recall: 0.3431\n",
            "Epoch 284/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1537 - accuracy: 0.5634 - precision: 0.7528 - recall: 0.3716 - val_loss: 1.1171 - val_accuracy: 0.5759 - val_precision: 0.8004 - val_recall: 0.3563\n",
            "Epoch 285/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1586 - accuracy: 0.5633 - precision: 0.7517 - recall: 0.3695 - val_loss: 1.1416 - val_accuracy: 0.5668 - val_precision: 0.8076 - val_recall: 0.3366\n",
            "Epoch 286/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1589 - accuracy: 0.5660 - precision: 0.7473 - recall: 0.3741 - val_loss: 1.1155 - val_accuracy: 0.5776 - val_precision: 0.8101 - val_recall: 0.3535\n",
            "Epoch 287/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1548 - accuracy: 0.5679 - precision: 0.7519 - recall: 0.3735 - val_loss: 1.1106 - val_accuracy: 0.5843 - val_precision: 0.8186 - val_recall: 0.3394\n",
            "Epoch 288/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1492 - accuracy: 0.5641 - precision: 0.7552 - recall: 0.3724 - val_loss: 1.0896 - val_accuracy: 0.5880 - val_precision: 0.8032 - val_recall: 0.3689\n",
            "Epoch 289/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1564 - accuracy: 0.5643 - precision: 0.7555 - recall: 0.3689 - val_loss: 1.1157 - val_accuracy: 0.5848 - val_precision: 0.8162 - val_recall: 0.3513\n",
            "Epoch 290/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1521 - accuracy: 0.5657 - precision: 0.7483 - recall: 0.3730 - val_loss: 1.1205 - val_accuracy: 0.5765 - val_precision: 0.8091 - val_recall: 0.3531\n",
            "Epoch 291/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1504 - accuracy: 0.5670 - precision: 0.7530 - recall: 0.3743 - val_loss: 1.1241 - val_accuracy: 0.5777 - val_precision: 0.7822 - val_recall: 0.3567\n",
            "Epoch 292/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1496 - accuracy: 0.5698 - precision: 0.7509 - recall: 0.3782 - val_loss: 1.1407 - val_accuracy: 0.5698 - val_precision: 0.8178 - val_recall: 0.3287\n",
            "Epoch 293/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1543 - accuracy: 0.5640 - precision: 0.7527 - recall: 0.3734 - val_loss: 1.1502 - val_accuracy: 0.5717 - val_precision: 0.8324 - val_recall: 0.3146\n",
            "Epoch 294/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1569 - accuracy: 0.5671 - precision: 0.7493 - recall: 0.3728 - val_loss: 1.1150 - val_accuracy: 0.5791 - val_precision: 0.8009 - val_recall: 0.3619\n",
            "Epoch 295/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1606 - accuracy: 0.5656 - precision: 0.7521 - recall: 0.3710 - val_loss: 1.1134 - val_accuracy: 0.5815 - val_precision: 0.8162 - val_recall: 0.3537\n",
            "Epoch 296/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1602 - accuracy: 0.5660 - precision: 0.7469 - recall: 0.3706 - val_loss: 1.1121 - val_accuracy: 0.5770 - val_precision: 0.8301 - val_recall: 0.3422\n",
            "Epoch 297/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.1594 - accuracy: 0.5648 - precision: 0.7486 - recall: 0.3731 - val_loss: 1.1382 - val_accuracy: 0.5762 - val_precision: 0.8249 - val_recall: 0.3345\n",
            "Epoch 298/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.1563 - accuracy: 0.5653 - precision: 0.7516 - recall: 0.3689 - val_loss: 1.1101 - val_accuracy: 0.5781 - val_precision: 0.7981 - val_recall: 0.3640\n",
            "Epoch 299/400\n",
            "897/897 [==============================] - 25s 28ms/step - loss: 1.1582 - accuracy: 0.5670 - precision: 0.7514 - recall: 0.3734 - val_loss: 1.1114 - val_accuracy: 0.5735 - val_precision: 0.7924 - val_recall: 0.3637\n",
            "Epoch 300/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1506 - accuracy: 0.5664 - precision: 0.7500 - recall: 0.3711 - val_loss: 1.1270 - val_accuracy: 0.5665 - val_precision: 0.7932 - val_recall: 0.3442\n",
            "Epoch 301/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1556 - accuracy: 0.5663 - precision: 0.7536 - recall: 0.3717 - val_loss: 1.1169 - val_accuracy: 0.5774 - val_precision: 0.8040 - val_recall: 0.3456\n",
            "Epoch 302/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1605 - accuracy: 0.5629 - precision: 0.7539 - recall: 0.3736 - val_loss: 1.1110 - val_accuracy: 0.5756 - val_precision: 0.8104 - val_recall: 0.3518\n",
            "Epoch 303/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1568 - accuracy: 0.5647 - precision: 0.7481 - recall: 0.3745 - val_loss: 1.1140 - val_accuracy: 0.5809 - val_precision: 0.8023 - val_recall: 0.3573\n",
            "Epoch 304/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1553 - accuracy: 0.5667 - precision: 0.7545 - recall: 0.3741 - val_loss: 1.1340 - val_accuracy: 0.5763 - val_precision: 0.8193 - val_recall: 0.3239\n",
            "Epoch 305/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1589 - accuracy: 0.5635 - precision: 0.7505 - recall: 0.3716 - val_loss: 1.1214 - val_accuracy: 0.5725 - val_precision: 0.8067 - val_recall: 0.3499\n",
            "Epoch 306/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1573 - accuracy: 0.5639 - precision: 0.7507 - recall: 0.3717 - val_loss: 1.1165 - val_accuracy: 0.5841 - val_precision: 0.8375 - val_recall: 0.3301\n",
            "Epoch 307/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1515 - accuracy: 0.5673 - precision: 0.7555 - recall: 0.3752 - val_loss: 1.1215 - val_accuracy: 0.5698 - val_precision: 0.7963 - val_recall: 0.3528\n",
            "Epoch 308/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1574 - accuracy: 0.5660 - precision: 0.7530 - recall: 0.3723 - val_loss: 1.1130 - val_accuracy: 0.5795 - val_precision: 0.7982 - val_recall: 0.3619\n",
            "Epoch 309/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1551 - accuracy: 0.5656 - precision: 0.7510 - recall: 0.3735 - val_loss: 1.1469 - val_accuracy: 0.5744 - val_precision: 0.8305 - val_recall: 0.3192\n",
            "Epoch 310/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1499 - accuracy: 0.5634 - precision: 0.7531 - recall: 0.3739 - val_loss: 1.1171 - val_accuracy: 0.5802 - val_precision: 0.8111 - val_recall: 0.3576\n",
            "Epoch 311/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1502 - accuracy: 0.5696 - precision: 0.7526 - recall: 0.3773 - val_loss: 1.1126 - val_accuracy: 0.5790 - val_precision: 0.8198 - val_recall: 0.3484\n",
            "Epoch 312/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1576 - accuracy: 0.5685 - precision: 0.7523 - recall: 0.3695 - val_loss: 1.1310 - val_accuracy: 0.5749 - val_precision: 0.8083 - val_recall: 0.3324\n",
            "Epoch 313/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1478 - accuracy: 0.5702 - precision: 0.7524 - recall: 0.3777 - val_loss: 1.1106 - val_accuracy: 0.5734 - val_precision: 0.7902 - val_recall: 0.3578\n",
            "Epoch 314/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1450 - accuracy: 0.5661 - precision: 0.7503 - recall: 0.3782 - val_loss: 1.1238 - val_accuracy: 0.5716 - val_precision: 0.8126 - val_recall: 0.3394\n",
            "Epoch 315/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1563 - accuracy: 0.5662 - precision: 0.7502 - recall: 0.3720 - val_loss: 1.1300 - val_accuracy: 0.5689 - val_precision: 0.8003 - val_recall: 0.3394\n",
            "Epoch 316/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1535 - accuracy: 0.5689 - precision: 0.7525 - recall: 0.3728 - val_loss: 1.1193 - val_accuracy: 0.5727 - val_precision: 0.7964 - val_recall: 0.3666\n",
            "Epoch 317/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1543 - accuracy: 0.5663 - precision: 0.7531 - recall: 0.3750 - val_loss: 1.1152 - val_accuracy: 0.5801 - val_precision: 0.7971 - val_recall: 0.3651\n",
            "Epoch 318/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1524 - accuracy: 0.5690 - precision: 0.7524 - recall: 0.3753 - val_loss: 1.1403 - val_accuracy: 0.5806 - val_precision: 0.8232 - val_recall: 0.3287\n",
            "Epoch 319/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1560 - accuracy: 0.5640 - precision: 0.7424 - recall: 0.3691 - val_loss: 1.1283 - val_accuracy: 0.5752 - val_precision: 0.8147 - val_recall: 0.3465\n",
            "Epoch 320/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1514 - accuracy: 0.5679 - precision: 0.7513 - recall: 0.3742 - val_loss: 1.1341 - val_accuracy: 0.5824 - val_precision: 0.8425 - val_recall: 0.3097\n",
            "Epoch 321/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1473 - accuracy: 0.5649 - precision: 0.7479 - recall: 0.3783 - val_loss: 1.1106 - val_accuracy: 0.5845 - val_precision: 0.8053 - val_recall: 0.3577\n",
            "Epoch 322/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1485 - accuracy: 0.5666 - precision: 0.7536 - recall: 0.3736 - val_loss: 1.1005 - val_accuracy: 0.5811 - val_precision: 0.8217 - val_recall: 0.3517\n",
            "Epoch 323/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1547 - accuracy: 0.5681 - precision: 0.7548 - recall: 0.3746 - val_loss: 1.1162 - val_accuracy: 0.5770 - val_precision: 0.7929 - val_recall: 0.3620\n",
            "Epoch 324/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1560 - accuracy: 0.5633 - precision: 0.7551 - recall: 0.3705 - val_loss: 1.1335 - val_accuracy: 0.5773 - val_precision: 0.8263 - val_recall: 0.3211\n",
            "Epoch 325/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1506 - accuracy: 0.5683 - precision: 0.7534 - recall: 0.3721 - val_loss: 1.1068 - val_accuracy: 0.5805 - val_precision: 0.7971 - val_recall: 0.3606\n",
            "Epoch 326/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1496 - accuracy: 0.5686 - precision: 0.7523 - recall: 0.3745 - val_loss: 1.1125 - val_accuracy: 0.5780 - val_precision: 0.7867 - val_recall: 0.3570\n",
            "Epoch 327/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1498 - accuracy: 0.5671 - precision: 0.7511 - recall: 0.3753 - val_loss: 1.1122 - val_accuracy: 0.5808 - val_precision: 0.7892 - val_recall: 0.3599\n",
            "Epoch 328/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1533 - accuracy: 0.5681 - precision: 0.7535 - recall: 0.3769 - val_loss: 1.1050 - val_accuracy: 0.5875 - val_precision: 0.8122 - val_recall: 0.3535\n",
            "Epoch 329/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1503 - accuracy: 0.5662 - precision: 0.7517 - recall: 0.3764 - val_loss: 1.1355 - val_accuracy: 0.5748 - val_precision: 0.8221 - val_recall: 0.3191\n",
            "Epoch 330/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1536 - accuracy: 0.5670 - precision: 0.7565 - recall: 0.3741 - val_loss: 1.1132 - val_accuracy: 0.5833 - val_precision: 0.7883 - val_recall: 0.3658\n",
            "Epoch 331/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1471 - accuracy: 0.5728 - precision: 0.7509 - recall: 0.3793 - val_loss: 1.1086 - val_accuracy: 0.5868 - val_precision: 0.8162 - val_recall: 0.3408\n",
            "Epoch 332/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1571 - accuracy: 0.5658 - precision: 0.7534 - recall: 0.3716 - val_loss: 1.1030 - val_accuracy: 0.5824 - val_precision: 0.8077 - val_recall: 0.3521\n",
            "Epoch 333/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1520 - accuracy: 0.5675 - precision: 0.7524 - recall: 0.3769 - val_loss: 1.1136 - val_accuracy: 0.5758 - val_precision: 0.8011 - val_recall: 0.3612\n",
            "Epoch 334/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1459 - accuracy: 0.5667 - precision: 0.7476 - recall: 0.3774 - val_loss: 1.1275 - val_accuracy: 0.5753 - val_precision: 0.8201 - val_recall: 0.3306\n",
            "Epoch 335/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1439 - accuracy: 0.5695 - precision: 0.7529 - recall: 0.3788 - val_loss: 1.1144 - val_accuracy: 0.5836 - val_precision: 0.8110 - val_recall: 0.3485\n",
            "Epoch 336/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1533 - accuracy: 0.5654 - precision: 0.7484 - recall: 0.3716 - val_loss: 1.1082 - val_accuracy: 0.5808 - val_precision: 0.8086 - val_recall: 0.3472\n",
            "Epoch 337/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1523 - accuracy: 0.5666 - precision: 0.7513 - recall: 0.3734 - val_loss: 1.1195 - val_accuracy: 0.5787 - val_precision: 0.8179 - val_recall: 0.3422\n",
            "Epoch 338/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1568 - accuracy: 0.5647 - precision: 0.7469 - recall: 0.3705 - val_loss: 1.1106 - val_accuracy: 0.5838 - val_precision: 0.8092 - val_recall: 0.3525\n",
            "Epoch 339/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1495 - accuracy: 0.5651 - precision: 0.7473 - recall: 0.3733 - val_loss: 1.1294 - val_accuracy: 0.5689 - val_precision: 0.8123 - val_recall: 0.3327\n",
            "Epoch 340/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1444 - accuracy: 0.5708 - precision: 0.7569 - recall: 0.3787 - val_loss: 1.1103 - val_accuracy: 0.5854 - val_precision: 0.8020 - val_recall: 0.3555\n",
            "Epoch 341/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1437 - accuracy: 0.5725 - precision: 0.7486 - recall: 0.3791 - val_loss: 1.1022 - val_accuracy: 0.5857 - val_precision: 0.8095 - val_recall: 0.3605\n",
            "Epoch 342/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1510 - accuracy: 0.5701 - precision: 0.7526 - recall: 0.3743 - val_loss: 1.1174 - val_accuracy: 0.5824 - val_precision: 0.8169 - val_recall: 0.3299\n",
            "Epoch 343/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1414 - accuracy: 0.5678 - precision: 0.7553 - recall: 0.3811 - val_loss: 1.1276 - val_accuracy: 0.5755 - val_precision: 0.8245 - val_recall: 0.3355\n",
            "Epoch 344/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1533 - accuracy: 0.5667 - precision: 0.7486 - recall: 0.3706 - val_loss: 1.1028 - val_accuracy: 0.5824 - val_precision: 0.8083 - val_recall: 0.3676\n",
            "Epoch 345/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1545 - accuracy: 0.5666 - precision: 0.7520 - recall: 0.3773 - val_loss: 1.1247 - val_accuracy: 0.5732 - val_precision: 0.8109 - val_recall: 0.3417\n",
            "Epoch 346/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1504 - accuracy: 0.5693 - precision: 0.7544 - recall: 0.3756 - val_loss: 1.0946 - val_accuracy: 0.5797 - val_precision: 0.7814 - val_recall: 0.3725\n",
            "Epoch 347/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1552 - accuracy: 0.5705 - precision: 0.7531 - recall: 0.3742 - val_loss: 1.1043 - val_accuracy: 0.5840 - val_precision: 0.8021 - val_recall: 0.3534\n",
            "Epoch 348/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1458 - accuracy: 0.5677 - precision: 0.7560 - recall: 0.3808 - val_loss: 1.1072 - val_accuracy: 0.5816 - val_precision: 0.7972 - val_recall: 0.3637\n",
            "Epoch 349/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1444 - accuracy: 0.5707 - precision: 0.7519 - recall: 0.3788 - val_loss: 1.0940 - val_accuracy: 0.5893 - val_precision: 0.8128 - val_recall: 0.3585\n",
            "Epoch 350/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1486 - accuracy: 0.5650 - precision: 0.7489 - recall: 0.3791 - val_loss: 1.1096 - val_accuracy: 0.5827 - val_precision: 0.8210 - val_recall: 0.3398\n",
            "Epoch 351/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1461 - accuracy: 0.5671 - precision: 0.7506 - recall: 0.3762 - val_loss: 1.1340 - val_accuracy: 0.5823 - val_precision: 0.8319 - val_recall: 0.3140\n",
            "Epoch 352/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1490 - accuracy: 0.5678 - precision: 0.7508 - recall: 0.3737 - val_loss: 1.1122 - val_accuracy: 0.5752 - val_precision: 0.7880 - val_recall: 0.3677\n",
            "Epoch 353/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1491 - accuracy: 0.5688 - precision: 0.7509 - recall: 0.3751 - val_loss: 1.1134 - val_accuracy: 0.5790 - val_precision: 0.7823 - val_recall: 0.3669\n",
            "Epoch 354/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1508 - accuracy: 0.5657 - precision: 0.7510 - recall: 0.3772 - val_loss: 1.1050 - val_accuracy: 0.5872 - val_precision: 0.8033 - val_recall: 0.3538\n",
            "Epoch 355/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1465 - accuracy: 0.5682 - precision: 0.7488 - recall: 0.3783 - val_loss: 1.1084 - val_accuracy: 0.5829 - val_precision: 0.8147 - val_recall: 0.3435\n",
            "Epoch 356/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1438 - accuracy: 0.5674 - precision: 0.7539 - recall: 0.3764 - val_loss: 1.1070 - val_accuracy: 0.5822 - val_precision: 0.8050 - val_recall: 0.3524\n",
            "Epoch 357/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1427 - accuracy: 0.5705 - precision: 0.7515 - recall: 0.3799 - val_loss: 1.1417 - val_accuracy: 0.5834 - val_precision: 0.7937 - val_recall: 0.3359\n",
            "Epoch 358/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1407 - accuracy: 0.5704 - precision: 0.7485 - recall: 0.3827 - val_loss: 1.1281 - val_accuracy: 0.5827 - val_precision: 0.8138 - val_recall: 0.3280\n",
            "Epoch 359/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1481 - accuracy: 0.5640 - precision: 0.7469 - recall: 0.3777 - val_loss: 1.1076 - val_accuracy: 0.5790 - val_precision: 0.8093 - val_recall: 0.3581\n",
            "Epoch 360/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1454 - accuracy: 0.5705 - precision: 0.7590 - recall: 0.3788 - val_loss: 1.0988 - val_accuracy: 0.5847 - val_precision: 0.8168 - val_recall: 0.3551\n",
            "Epoch 361/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1466 - accuracy: 0.5670 - precision: 0.7527 - recall: 0.3789 - val_loss: 1.1063 - val_accuracy: 0.5815 - val_precision: 0.7899 - val_recall: 0.3735\n",
            "Epoch 362/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1418 - accuracy: 0.5738 - precision: 0.7478 - recall: 0.3803 - val_loss: 1.1064 - val_accuracy: 0.5824 - val_precision: 0.7983 - val_recall: 0.3571\n",
            "Epoch 363/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1469 - accuracy: 0.5697 - precision: 0.7524 - recall: 0.3788 - val_loss: 1.1057 - val_accuracy: 0.5910 - val_precision: 0.8195 - val_recall: 0.3453\n",
            "Epoch 364/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1386 - accuracy: 0.5713 - precision: 0.7520 - recall: 0.3845 - val_loss: 1.1196 - val_accuracy: 0.5826 - val_precision: 0.8034 - val_recall: 0.3347\n",
            "Epoch 365/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1437 - accuracy: 0.5691 - precision: 0.7513 - recall: 0.3796 - val_loss: 1.1142 - val_accuracy: 0.5774 - val_precision: 0.8091 - val_recall: 0.3484\n",
            "Epoch 366/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1439 - accuracy: 0.5745 - precision: 0.7505 - recall: 0.3811 - val_loss: 1.1035 - val_accuracy: 0.5897 - val_precision: 0.8122 - val_recall: 0.3444\n",
            "Epoch 367/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1448 - accuracy: 0.5713 - precision: 0.7477 - recall: 0.3785 - val_loss: 1.1381 - val_accuracy: 0.5696 - val_precision: 0.7770 - val_recall: 0.3481\n",
            "Epoch 368/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1438 - accuracy: 0.5747 - precision: 0.7554 - recall: 0.3804 - val_loss: 1.1119 - val_accuracy: 0.5841 - val_precision: 0.7634 - val_recall: 0.3929\n",
            "Epoch 369/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1474 - accuracy: 0.5720 - precision: 0.7512 - recall: 0.3836 - val_loss: 1.1150 - val_accuracy: 0.5833 - val_precision: 0.8147 - val_recall: 0.3440\n",
            "Epoch 370/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1452 - accuracy: 0.5670 - precision: 0.7551 - recall: 0.3770 - val_loss: 1.1064 - val_accuracy: 0.5791 - val_precision: 0.7964 - val_recall: 0.3569\n",
            "Epoch 371/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1496 - accuracy: 0.5674 - precision: 0.7533 - recall: 0.3778 - val_loss: 1.1016 - val_accuracy: 0.5887 - val_precision: 0.8082 - val_recall: 0.3486\n",
            "Epoch 372/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1453 - accuracy: 0.5669 - precision: 0.7544 - recall: 0.3764 - val_loss: 1.1093 - val_accuracy: 0.5794 - val_precision: 0.8063 - val_recall: 0.3544\n",
            "Epoch 373/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1436 - accuracy: 0.5720 - precision: 0.7543 - recall: 0.3777 - val_loss: 1.1050 - val_accuracy: 0.5811 - val_precision: 0.7964 - val_recall: 0.3546\n",
            "Epoch 374/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1411 - accuracy: 0.5732 - precision: 0.7551 - recall: 0.3823 - val_loss: 1.1072 - val_accuracy: 0.5820 - val_precision: 0.7924 - val_recall: 0.3648\n",
            "Epoch 375/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1419 - accuracy: 0.5677 - precision: 0.7526 - recall: 0.3786 - val_loss: 1.0989 - val_accuracy: 0.5773 - val_precision: 0.7918 - val_recall: 0.3736\n",
            "Epoch 376/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1494 - accuracy: 0.5705 - precision: 0.7541 - recall: 0.3757 - val_loss: 1.0942 - val_accuracy: 0.5818 - val_precision: 0.7941 - val_recall: 0.3765\n",
            "Epoch 377/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1476 - accuracy: 0.5691 - precision: 0.7528 - recall: 0.3784 - val_loss: 1.1165 - val_accuracy: 0.5763 - val_precision: 0.8011 - val_recall: 0.3495\n",
            "Epoch 378/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1390 - accuracy: 0.5745 - precision: 0.7545 - recall: 0.3863 - val_loss: 1.1192 - val_accuracy: 0.5746 - val_precision: 0.7798 - val_recall: 0.3622\n",
            "Epoch 379/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1431 - accuracy: 0.5701 - precision: 0.7516 - recall: 0.3753 - val_loss: 1.1028 - val_accuracy: 0.5799 - val_precision: 0.7717 - val_recall: 0.3871\n",
            "Epoch 380/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1436 - accuracy: 0.5728 - precision: 0.7524 - recall: 0.3842 - val_loss: 1.1208 - val_accuracy: 0.5826 - val_precision: 0.8086 - val_recall: 0.3496\n",
            "Epoch 381/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1424 - accuracy: 0.5722 - precision: 0.7552 - recall: 0.3793 - val_loss: 1.1046 - val_accuracy: 0.5778 - val_precision: 0.7781 - val_recall: 0.3792\n",
            "Epoch 382/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1410 - accuracy: 0.5686 - precision: 0.7526 - recall: 0.3832 - val_loss: 1.0982 - val_accuracy: 0.5833 - val_precision: 0.7966 - val_recall: 0.3747\n",
            "Epoch 383/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1485 - accuracy: 0.5689 - precision: 0.7534 - recall: 0.3763 - val_loss: 1.0937 - val_accuracy: 0.5884 - val_precision: 0.7942 - val_recall: 0.3687\n",
            "Epoch 384/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1392 - accuracy: 0.5738 - precision: 0.7540 - recall: 0.3836 - val_loss: 1.1075 - val_accuracy: 0.5854 - val_precision: 0.8048 - val_recall: 0.3451\n",
            "Epoch 385/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1476 - accuracy: 0.5713 - precision: 0.7493 - recall: 0.3780 - val_loss: 1.1270 - val_accuracy: 0.5778 - val_precision: 0.8236 - val_recall: 0.3329\n",
            "Epoch 386/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1433 - accuracy: 0.5701 - precision: 0.7550 - recall: 0.3796 - val_loss: 1.1017 - val_accuracy: 0.5866 - val_precision: 0.8031 - val_recall: 0.3624\n",
            "Epoch 387/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1399 - accuracy: 0.5719 - precision: 0.7537 - recall: 0.3821 - val_loss: 1.0982 - val_accuracy: 0.5878 - val_precision: 0.8177 - val_recall: 0.3497\n",
            "Epoch 388/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1395 - accuracy: 0.5739 - precision: 0.7529 - recall: 0.3846 - val_loss: 1.1234 - val_accuracy: 0.5762 - val_precision: 0.8222 - val_recall: 0.3343\n",
            "Epoch 389/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1473 - accuracy: 0.5712 - precision: 0.7524 - recall: 0.3800 - val_loss: 1.1075 - val_accuracy: 0.5850 - val_precision: 0.8162 - val_recall: 0.3439\n",
            "Epoch 390/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1456 - accuracy: 0.5713 - precision: 0.7492 - recall: 0.3770 - val_loss: 1.1273 - val_accuracy: 0.5790 - val_precision: 0.8308 - val_recall: 0.3255\n",
            "Epoch 391/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1483 - accuracy: 0.5715 - precision: 0.7521 - recall: 0.3799 - val_loss: 1.1048 - val_accuracy: 0.5801 - val_precision: 0.8130 - val_recall: 0.3493\n",
            "Epoch 392/400\n",
            "897/897 [==============================] - 27s 30ms/step - loss: 1.1441 - accuracy: 0.5692 - precision: 0.7537 - recall: 0.3744 - val_loss: 1.1207 - val_accuracy: 0.5785 - val_precision: 0.7820 - val_recall: 0.3664\n",
            "Epoch 393/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1373 - accuracy: 0.5723 - precision: 0.7531 - recall: 0.3863 - val_loss: 1.1223 - val_accuracy: 0.5792 - val_precision: 0.7876 - val_recall: 0.3620\n",
            "Epoch 394/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1480 - accuracy: 0.5721 - precision: 0.7527 - recall: 0.3788 - val_loss: 1.1017 - val_accuracy: 0.5864 - val_precision: 0.8010 - val_recall: 0.3677\n",
            "Epoch 395/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1451 - accuracy: 0.5710 - precision: 0.7560 - recall: 0.3820 - val_loss: 1.1181 - val_accuracy: 0.5808 - val_precision: 0.8159 - val_recall: 0.3419\n",
            "Epoch 396/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1422 - accuracy: 0.5670 - precision: 0.7531 - recall: 0.3817 - val_loss: 1.1296 - val_accuracy: 0.5760 - val_precision: 0.8259 - val_recall: 0.3276\n",
            "Epoch 397/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1406 - accuracy: 0.5721 - precision: 0.7528 - recall: 0.3823 - val_loss: 1.1293 - val_accuracy: 0.5770 - val_precision: 0.8153 - val_recall: 0.3276\n",
            "Epoch 398/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1476 - accuracy: 0.5695 - precision: 0.7543 - recall: 0.3795 - val_loss: 1.1082 - val_accuracy: 0.5864 - val_precision: 0.8095 - val_recall: 0.3457\n",
            "Epoch 399/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1437 - accuracy: 0.5704 - precision: 0.7542 - recall: 0.3856 - val_loss: 1.0993 - val_accuracy: 0.5898 - val_precision: 0.8188 - val_recall: 0.3605\n",
            "Epoch 400/400\n",
            "897/897 [==============================] - 26s 29ms/step - loss: 1.1472 - accuracy: 0.5712 - precision: 0.7526 - recall: 0.3813 - val_loss: 1.1151 - val_accuracy: 0.5838 - val_precision: 0.8132 - val_recall: 0.3443\n"
          ]
        }
      ],
      "source": [
        " history = model.fit(\n",
        "    train_data,\n",
        "    steps_per_epoch = train_data.samples//BATCH_SIZE,\n",
        "    epochs = 400,\n",
        "    validation_data = validation_data,\n",
        "    validation_steps = validation_data.samples//BATCH_SIZE\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPZ5kcs8ouXx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "export_dir = '/tmp/saved_model'\n",
        "tf.saved_model.save(model, export_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaJEOCgtwBJ2",
        "outputId": "267e287c-9d3a-4817-c573-0f7ef627363e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}